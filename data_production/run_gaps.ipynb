{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66173b3c",
   "metadata": {},
   "source": [
    "# Generate AIS reception and gap events datasets\n",
    "\n",
    "This notebook is a wrapper file for producing a complete set of results and inputs for Welch et al. (2021). It contains code for the following: \n",
    "\n",
    "1. Generate raw AIS gap events greater than 12 hours\n",
    "2. Generate monthly AIS reception maps\n",
    "3. Detect suspected AIS disabling events\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49306b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "from datetime import datetime, timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "from google.cloud import bigquery\n",
    "from jinja2 import Template\n",
    "\n",
    "import pyseas\n",
    "import pyseas.maps\n",
    "import pyseas.maps.rasters\n",
    "import pyseas.styles\n",
    "import pyseas.cm\n",
    "\n",
    "# project specific functions\n",
    "import utils \n",
    "\n",
    "%load_ext autoreload\n",
    "%load_ext google.cloud.bigquery\n",
    "%autoreload 2\n",
    "\n",
    "# BigQuery client\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdba993",
   "metadata": {},
   "source": [
    "### Inputs & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input BQ datasets/tables\n",
    "gfw_research = 'gfw_research'\n",
    "gfw_research_precursors = 'gfw_research_precursors'\n",
    "proj_dataset = 'proj_ais_gaps_catena'\n",
    "destination_dataset = 'scratch_tyler'\n",
    "\n",
    "pipeline_version = 'v20201001'\n",
    "pipeline_table = 'pipe_{}'.format(pipeline_version)\n",
    "segs_table = 'pipe_{}_segs'.format(pipeline_version)\n",
    "vi_version = 'v20210301'\n",
    "vd_version = 'v20210601'\n",
    "\n",
    "# Output tables version\n",
    "output_version = 'v20210722'\n",
    "create_tables = True\n",
    "\n",
    "# Date range\n",
    "start_date = date(2017,1, 1)\n",
    "end_date = date(2020,12, 31)\n",
    "\n",
    "# Min gap hours\n",
    "min_gap_hours = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e18d65",
   "metadata": {},
   "source": [
    "Generate list of dates to produce for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of dates to run\n",
    "dates_to_run = utils.daterange(start_date, end_date)\n",
    "tp = []\n",
    "for dt in dates_to_run:\n",
    "    tp.append(dt.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68760d3",
   "metadata": {},
   "source": [
    "# AIS Gaps dataset\n",
    "\n",
    "Generate a dataset of AIS gaps for time range. This involves running the following query sequence (queries in the `gaps` subdirectory):\n",
    "1. AIS off events: `ais_off_on_events.sql.j2` with `event` parameter set to `'off'`\n",
    "2. AIS on events: `ais_off_on_events.sql.j2` with `event` parameter set to `'on'`\n",
    "3. AIS gap events: Stitch off and on events together into gap events using `ais_gap_events.sql.j2`\n",
    "\n",
    "### Create tables\n",
    "\n",
    "First, create empty tables for all three tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination tables\n",
    "off_events_table = 'ais_off_events_{}'.format(output_version)\n",
    "on_events_table = 'ais_on_events_{}'.format(output_version)\n",
    "gap_events_table = 'ais_gap_events_{}'.format(output_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30038b",
   "metadata": {},
   "source": [
    "Create tables for off/on events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_tables:\n",
    "    # Off events\n",
    "    utils.make_bq_partitioned_table(destination_dataset, off_events_table)\n",
    "    # On events\n",
    "    utils.make_bq_partitioned_table(destination_dataset, on_events_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c39915",
   "metadata": {},
   "source": [
    "### Off events\n",
    "\n",
    "Generate off events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ab07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store commands\n",
    "cmds = []\n",
    "for t in tp:\n",
    "    cmd = utils.make_ais_events_table(pipeline_table=\"{}.{}\".format(\"gfw_research\", pipeline_table),\n",
    "                                segs_table=\"{}.{}\".format(\"gfw_research\", segs_table),\n",
    "                                event_type='off',\n",
    "                                date = t,\n",
    "                                min_gap_hours = min_gap_hours, \n",
    "                                precursors_dataset=destination_dataset,\n",
    "                                destination_table=off_events_table)\n",
    "    cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990beba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query\n",
    "# test_cmd = cmds[0].split('|')[0]\n",
    "# os.system(test_cmd)\n",
    "# os.system(cmds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56eeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run queries\n",
    "utils.execute_commands_in_parallel(commands=cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b70551",
   "metadata": {},
   "source": [
    "### On events\n",
    "\n",
    "Generate on events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5175b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store commands\n",
    "on_cmds = []\n",
    "for t in tp:\n",
    "    cmd = utils.make_ais_events_table(pipeline_table=\"{}.{}\".format(\"gfw_research\", pipeline_table),\n",
    "                                segs_table=\"{}.{}\".format(\"gfw_research\", segs_table),\n",
    "                                event_type='on',\n",
    "                                date = t,\n",
    "                                min_gap_hours = min_gap_hours, \n",
    "                                precursors_dataset=destination_dataset,\n",
    "                                destination_table=on_events_table)\n",
    "    on_cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22526c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query\n",
    "# test_cmd = on_cmds[0].split('|')[0]\n",
    "# os.system(test_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run queries\n",
    "utils.execute_commands_in_parallel(commands=on_cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d7a90",
   "metadata": {},
   "source": [
    "### Gap events\n",
    "\n",
    "Combine off and on events into gap events.\n",
    "\n",
    "Create gap events table, partitioning on the `gap_start` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fbcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_tables:\n",
    "    gap_tbl_cmd = \"bq mk --schema=gaps/ais_gap_events.json \\\n",
    "    --time_partitioning_field=gap_start \\\n",
    "    --time_partitioning_type=DAY {}.{}\".format(destination_dataset, \n",
    "                                               gap_events_table)\n",
    "    os.system(gap_tbl_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date = tp[-1]\n",
    "gap_cmd = utils.make_ais_gap_events_table(off_events_table = off_events_table,\n",
    "                                on_events_table = on_events_table,\n",
    "                                date = latest_date,\n",
    "                                precursors_dataset = destination_dataset,\n",
    "                                destination_dataset = destination_dataset,\n",
    "                                destination_table = gap_events_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14807fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query\n",
    "# test_cmd = gap_cmd.split('|')[0]\n",
    "# os.system(test_cmd)\n",
    "# os.system(test_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run command\n",
    "os.system(gap_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update schema\n",
    "gap_schema_cmd = \"bq update --schema=gaps/ais_gap_events.json {}.{}\".format(destination_dataset, gap_events_table)\n",
    "os.system(gap_schema_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac6c76",
   "metadata": {},
   "source": [
    "### Fishing vessel gaps\n",
    "\n",
    "Lastly, create the final gaps model dataset by doing the following:\n",
    "\n",
    "+ subset the `ais_gap_events_vYYYYMMDD` dataset to only include fishing vessels \n",
    "+ Add additional model variables not calculated at the time of the gap events creation:\n",
    "    + pos\n",
    "\n",
    "**TODO** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54e84d",
   "metadata": {},
   "source": [
    "# Loitering\n",
    "Produce datasets of loitering events and gridded loitering activity (at quarter degree) for use by the drivers of suspected disabling model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination tables\n",
    "loitering_events_table = 'loitering_events_{}'.format(output_version)\n",
    "gridded_loitering_table = 'gridded_loitering_{}'.format(output_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e94bc1",
   "metadata": {},
   "source": [
    "## Loitering events and gridded loitering\n",
    "\n",
    "Query all carrier loitering events between 2017-2019. This query does not exclude loitering events that have overlapping encounters under the assumption that carrier vessels having encounters could also be meeting non-broadcasting fishing vessels at the same time. \n",
    "\n",
    "After extracting events, produce a gridded dataset of all loitering events at quarter degree resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c184b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loitering_cmd = utils.make_loitering_events_table(vd_version = vd_version,\n",
    "                                                  pipeline_version = pipeline_version,\n",
    "                                                  destination_dataset = destination_dataset,\n",
    "                                                  destination_table = loitering_events_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run query\n",
    "if create_tables:\n",
    "    os.system(loitering_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19adbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_loitering_cmd = utils.make_gridded_loitering_table(destination_dataset = proj_dataset,\n",
    "                                                           output_version = output_version,\n",
    "                                                           destination_table = gridded_loitering_table)\n",
    "gridded_loitering_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_tables:\n",
    "    os.system(gridded_loitering_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8988a",
   "metadata": {},
   "source": [
    "## Fishing\n",
    "\n",
    "Produce dataset of gridded fishing effort (at quarter degree) for use by the drivers of suspected disabling model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination tables\n",
    "fishing_table = 'gridded_fishing_{}'.format(output_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d390b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fishing_cmd = utils.make_gridded_fishing_table(output_version = output_version,\n",
    "                                               pipeline_version = pipeline_version,\n",
    "                                               vi_version = vi_version,\n",
    "                                               destination_dataset = destination_dataset,\n",
    "                                               destination_table = fishing_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query\n",
    "# test_cmd = fishing_cmd.split('|')[0]\n",
    "# test_cmd\n",
    "# os.system(test_cmd)\n",
    "# fishing_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcfc293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run query\n",
    "if create_tables:\n",
    "    os.system(fishing_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a9204c",
   "metadata": {},
   "source": [
    "# AIS Interpolation\n",
    "\n",
    "The next step is to generate tables of interpolated vessel positions. These tables are used subsequently for the following:\n",
    "- AIS reception\n",
    "- Time lost to gaps\n",
    "\n",
    "> The original reception quality method used a slightly different interpolation [query](https://github.com/GlobalFishingWatch/ais-gaps-and-reception/blob/master/data-production/hourly_interpoloation_v20191120.sql.j2)/table (`gfw_research_precursors.ais_positions_byssvid_hourly_v20191118`) than the [query](https://github.com/GlobalFishingWatch/ais-gaps-and-reception/blob/master/data-production/pipe-interpolation/hourly_interpoloation_v20201027.sql.j2) used to estimate time lost to gaps. These approaches have been combined/streamlined into the `interpolation/hourly_interpolation_byseg.sql.j2` in this repo.\n",
    "\n",
    "### Create tables\n",
    "\n",
    "First create empty date partitioned tables to store interpolated positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination tables\n",
    "# ais_positions_hourly = 'ais_positions_byssvid_hourly_{}'.format(output_version)\n",
    "# By seg_id\n",
    "ais_positions_hourly = 'ais_positions_byseg_hourly_{}'.format(output_version)\n",
    "\n",
    "ais_positions_hourly_fishing = 'ais_positions_byssvid_hourly_fishing_{}'.format(output_version)\n",
    "gap_positions_hourly = 'gap_positions_byssvid_hourly_{}'.format(output_version)\n",
    "loitering_positions_hourly = 'loitering_positions_byssvid_hourly_{}'.format(output_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_tables:\n",
    "    # all positions hourly\n",
    "    utils.make_bq_partitioned_table(destination_dataset, ais_positions_hourly)\n",
    "    # fishing vessel positions hourly\n",
    "    utils.make_bq_partitioned_table(destination_dataset, ais_positions_hourly_fishing)\n",
    "    # gap positions hourly\n",
    "    utils.make_bq_partitioned_table(destination_dataset, gap_positions_hourly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daaf3b4",
   "metadata": {},
   "source": [
    "### Interpolate all vessel positions\n",
    "\n",
    "Interpolate positions for all vessels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store commands\n",
    "int_cmds = []\n",
    "for t in tp:\n",
    "    cmd = utils.make_hourly_interpolation_table(date = t,\n",
    "                                                destination_dataset = destination_dataset,\n",
    "                                                destination_table = ais_positions_hourly)\n",
    "    int_cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9787473",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.execute_commands_in_parallel(int_cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec71817",
   "metadata": {},
   "source": [
    "### Interpolate fishing vessel positions\n",
    "Interpolate positions for fishing vessels, including both `nnet_score` and `night_loitering` for determining when `squid_jiggers` are fishing.\n",
    "\n",
    "TODO: Update this to the same logic as for all vessels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store commands\n",
    "# int_fishing_cmds = []\n",
    "# for t in tp:\n",
    "#     cmd = utils.make_hourly_fishing_interpolation_table(date = t,\n",
    "#                                                 destination_dataset = destination_dataset,\n",
    "#                                                 destination_table = ais_positions_hourly_fishing)\n",
    "#     int_fishing_cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8842c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.execute_commands_in_parallel(int_fishing_cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c0efe0",
   "metadata": {},
   "source": [
    "### Interpolate positions during AIS gap events\n",
    "\n",
    "> **Note:** Interpolating positions between gap events was originally done using the `raw_gaps_vYYYYMMDD` table, which included the gaps with additional parameters applied to them - e.g. `pos_x_hours_before`. Need to produce a version of this table or interpolate the gap events as is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc4a5f5",
   "metadata": {},
   "source": [
    "## AIS Reception Quality\n",
    "\n",
    "Model AIS satellite reception quality to identify regions where AIS gap events are more/less suspicious. This is produced using the following process:\n",
    "\n",
    "**1. Calculate measured reception** - Calculates measured reception quality by AIS Class as the average number of positions received by a vessel in a day per one-degree grid cell\n",
    "\n",
    "**2. Interpolate reception** - To produce global maps of reception quality (e.g. not just in cells with AIS data) use a smoothing function to interpolate reception quality. \n",
    "\n",
    "### Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1d48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_reception_measured = 'sat_reception_measured_one_degree_{}'.format(output_version)\n",
    "sat_reception_smoothed = 'sat_reception_smoothed_one_degree_{}'.format(output_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e430740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_tables:\n",
    "    # measured reception quality\n",
    "    utils.make_bq_partitioned_table(destination_dataset, sat_reception_measured)\n",
    "    # smoothed reception quality\n",
    "    utils.make_bq_partitioned_table(destination_dataset, sat_reception_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad51e7",
   "metadata": {},
   "source": [
    "### Measured reception quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb52deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of month start dates for reception quality\n",
    "reception_dates = pd.date_range(start_date, end_date, freq='1M') - pd.offsets.MonthBegin(1)\n",
    "# reception_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate commands\n",
    "mr_cmds = []\n",
    "for r in reception_dates:\n",
    "#     print(str(r.date()))\n",
    "    cmd = utils.make_reception_measured_table(destination_table = sat_reception_measured, \n",
    "                                        destination_dataset = destination_dataset,\n",
    "                                        start_date = r, \n",
    "                                        vi_version = vi_version, \n",
    "                                        segs_table=\"{}.{}\".format(\"gfw_research\", segs_table),\n",
    "                                        output_version = output_version)\n",
    "\n",
    "    mr_cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95838fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.execute_commands_in_parallel(mr_cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2739644",
   "metadata": {},
   "source": [
    "### Smoothed reception quality\n",
    "\n",
    "Next, interpolate the measured reception quality using a radial basis function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1553bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in reception_dates:\n",
    "    print(str(r.date()))\n",
    "    utils.make_smooth_reception_table(start_date = r,\n",
    "                                      reception_measured_table = sat_reception_measured,\n",
    "                                      destination_dataset = destination_dataset,\n",
    "                                      destination_table = sat_reception_smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81db83",
   "metadata": {},
   "source": [
    "### Plot reception quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in reception_dates:\n",
    "    print(str(r.date()))\n",
    "    \"\"\"\n",
    "    Query smoothed reception data\n",
    "    \"\"\"\n",
    "    month_reception_query = '''SELECT *\n",
    "                               FROM `{d}.{t}`\n",
    "                               WHERE _partitiontime = \"{m}\"'''.format(d = destination_dataset,\n",
    "                                                                      t = sat_reception_smoothed,\n",
    "                                                                      m = str(r.date())\n",
    "                                                                     )\n",
    "    # Query data\n",
    "    month_reception = pd.read_gbq(month_reception_query, project_id='world-fishing-827', dialect='standard')\n",
    "    \n",
    "    utils.plot_reception_quality(reception_start_date = r,\n",
    "                                 destination_dataset = destination_dataset,\n",
    "                                 reception_smoothed_table = sat_reception_smoothed,\n",
    "                                 reception_df = month_reception\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa75bb",
   "metadata": {},
   "source": [
    "Plot average reception quality across the full time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1079d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Query smoothed reception data\n",
    "\"\"\"\n",
    "month_reception_query = '''SELECT \n",
    "                           lat_bin,\n",
    "                           lon_bin,\n",
    "                           class,\n",
    "                           AVG(positions_per_day) as positions_per_day\n",
    "                           FROM `{d}.{t}`\n",
    "                           WHERE _partitiontime BETWEEN \"2017-01-01\" \n",
    "                           AND \"2019-12-01\"\n",
    "                           GROUP BY 1,2,3'''.format(d = destination_dataset,\n",
    "                                                      t = sat_reception_smoothed)\n",
    "# Query data\n",
    "month_reception = pd.read_gbq(month_reception_query, project_id='world-fishing-827', dialect='standard')\n",
    "\n",
    "utils.plot_reception_quality(reception_start_date = r,\n",
    "                             destination_dataset = destination_dataset,\n",
    "                             reception_smoothed_table = sat_reception_smoothed,\n",
    "                             reception_df = month_reception\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314ef98",
   "metadata": {},
   "source": [
    "## Final gap events table\n",
    "\n",
    "Create the final gap events table that is used as an input to the model of suspected drivers of AIS disabling. This table takes the `ais_gap_events_vYYYYMMDD` table created above and adds a handful of additional model features, including the smoothed reception quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a785a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_events_features_table = 'ais_gap_events_features_{}'.format(output_version)\n",
    "gap_events_features_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_tables:\n",
    "    gap_features_tbl_cmd = \"bq mk --schema=gaps/ais_gap_events_features.json \\\n",
    "    --time_partitioning_field=gap_start \\\n",
    "    --time_partitioning_type=DAY {}.{}\".format(destination_dataset, \n",
    "                                               gap_events_features_table)\n",
    "    os.system(gap_features_tbl_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ae20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_features_cmd = utils.make_ais_gap_events_features_table(pipeline_version=pipeline_version,\n",
    "                                                   vi_version=vi_version,\n",
    "                                                   output_version=output_version,\n",
    "                                                   start_date=str(start_date),\n",
    "                                                   end_date=str(end_date),\n",
    "                                                   destination_dataset=destination_dataset,\n",
    "                                                   destination_table=gap_events_features_table)\n",
    "\n",
    "# gap_features_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2268138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test query\n",
    "# test_cmd = gap_features_cmd.split('|')[0]\n",
    "# os.system(test_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3337c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gap features query\n",
    "# WARNING: BIG QUERY (~3.5 TB)\n",
    "if create_tables:\n",
    "    os.system(gap_features_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4101bf0",
   "metadata": {},
   "source": [
    "# Copy Tables\n",
    "\n",
    "If needed, copy tables to a different BigQuery dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy destination dataset\n",
    "cp_destination_dataset = 'proj_ais_gaps_catena'\n",
    "\n",
    "# List of tables to copy\n",
    "tables_to_cp = [\n",
    "    off_events_table,\n",
    "    on_events_table,\n",
    "    gap_events_table,\n",
    "    gap_events_features_table,\n",
    "    loitering_events_table,\n",
    "    gridded_loitering_table,\n",
    "    fishing_table,\n",
    "    ais_positions_hourly,\n",
    "    sat_reception_measured,\n",
    "    sat_reception_smoothed\n",
    "]\n",
    "\n",
    "if copy_tables:\n",
    "    for t in tables_to_cp:\n",
    "\n",
    "        print('Copying {d}.{t} \\n to {cd}.{t}'.format(d = destination_dataset,\n",
    "                                                  cd = cp_destination_dataset,\n",
    "                                                  t = t))\n",
    "        # Format query\n",
    "        cp_cmd = \"\"\"bq cp -n \\\n",
    "        {d}.{t} \\\n",
    "        {cd}.{t}\"\"\".format(d = destination_dataset,\n",
    "                           cd = cp_destination_dataset,\n",
    "                           t = t)\n",
    "\n",
    "        # Run command\n",
    "        os.system(cp_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02ca0b7",
   "metadata": {},
   "source": [
    "# Download data\n",
    "\n",
    "Download the following datasets for us in the model to identify drivers of suspected disabling:\n",
    "+ Gap events with features\n",
    "+ Loitering events\n",
    "+ Gridded fishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb413deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results folder \n",
    "results_dir = \"../results\"\n",
    "# os.mkdir(results_dir)\n",
    "# Create folder for specific results version\n",
    "results_version_dir = os.path.join(results_dir, \"gap_inputs_{}\".format(output_version))\n",
    "# os.mkdir(results_version_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de15467",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery gap_events_features_df\n",
    "SELECT * \n",
    "FROM `world-fishing-827.scratch_tyler.ais_gap_events_features_v20210722` \n",
    "WHERE gap_hours >= 12\n",
    "AND gap_start < '2021-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_events_features_df.to_csv('gap_events_features_{}.csv'.format(output_version), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3707d",
   "metadata": {},
   "source": [
    "Download loitering events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b745566",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery loitering_events_df\n",
    "SELECT *\n",
    "FROM proj_ais_gaps_catena.loitering_events_v20210722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loitering_events_df.to_csv('{d}/loitering_events_v20210722.csv'.format(d = results_version_dir), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7c2ce",
   "metadata": {},
   "source": [
    "Gridded loitering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f37668",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery gridded_loitering_df\n",
    "SELECT *\n",
    "FROM proj_ais_gaps_catena.gridded_loitering_v20210722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae395450",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_loitering_df.to_csv('{d}/loitering_quarter_degree_v20210722_2017_to_2019.csv'.format(d = results_version_dir), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ad74f",
   "metadata": {},
   "source": [
    "Download gridded fishing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911eb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery gridded_fishing_df\n",
    "SELECT *\n",
    "FROM proj_ais_gaps_catena.gridded_fishing_v20210722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridded_fishing_df.to_csv('{d}/vessel_presence_quarter_degree_v20210722_2017_to_2019.csv'.format(d = results_version_dir), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6444440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
