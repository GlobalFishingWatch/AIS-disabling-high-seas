# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:light
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.13.0
#   kernelspec:
#     display_name: gfw-new
#     language: python
#     name: gfw-new
# ---

# ## The final query

q = """
SELECT *
FROM `world-fishing-827.proj_ais_gaps_catena.ais_gap_events_features_v20210722`
WHERE gap_hours >= 12
    AND (off_distance_from_shore_m > 1852*50 AND on_distance_from_shore_m > 1852*50)
    AND (positions_per_day_off > 5 AND positions_per_day_on > 5)
    AND (DATE(gap_start) >= '2017-01-01' AND DATE(gap_end) <= '2019-12-31')
    AND positions_X_hours_before_sat >= 19
"""

# ---

# +
import pandas as pd
from sklearn.model_selection import (
    train_test_split,
    cross_validate,
    GroupShuffleSplit,
    StratifiedShuffleSplit,
)
import sklearn.metrics as skm
from random import seed, randint
import numpy as np
from numpy import mean, std, concatenate
from scipy.stats import sem
import json

from importlib import reload
import threshold_models

reload(threshold_models)
from threshold_models import SingleThresholdClassifier, DoubleThresholdClassifier

models_folder = "models"
if not os.path.exists(models_folder):
    os.makedirs(models_folder)
# -


gaps_labeled = (
    f"world-fishing-827.proj_ais_gaps_catena.ais_gap_events_labeled_v20210722"
)

# +
q = f"""
SELECT
  *
FROM
  `{gaps_labeled}` 
WHERE
  (off_distance_from_shore_m >= 50*1852 AND on_distance_from_shore_m >= 50*1852)
  AND (positions_per_day_off > 5 AND positions_per_day_on > 5)
"""

df_gaps = pd.read_gbq(q, project_id="world-fishing-827", dialect="standard")
# -

print("Number unique MMSI:", df_gaps.ssvid.unique().shape[0])
print("Total gaps:", df_gaps.shape[0])

df_gaps.head(5)

# # Run Repeated KFold Cross Validation using GroupShuffleSplit to select best model
#

# ## Separate out training and test sets on 70-30 split, grouping by MMSI
#
# Since the gaps are grouped on MMSI, meaning that all of the gaps for an MMSI must either be fully in the training set OR the test set to prevent data leakage, getting an exact 70-30 split is not possible. The `test_size` parameter has been set to 0.22 after some experimentation as this gave the desired 70-30 split with `random_state` set to 5.

# +
train_idx, test_idx = next(
    GroupShuffleSplit(test_size=0.22, n_splits=2, random_state=5).split(
        df_gaps, groups=df_gaps.ssvid.to_numpy()
    )
)

df_gaps_train = df_gaps.iloc[train_idx]
df_gaps_test = df_gaps.iloc[test_idx]
print(
    f"The proportion of gaps used for testing and final performance metrics is actually {df_gaps_test.shape[0]/df_gaps_train.shape[0]:0.2f} due to the grouping"
)
# -

# #### Save to CSV for replicability

df_gaps_train.to_csv(f"{models_folder}/gaps_training_set.csv")
df_gaps_test.to_csv(f"{models_folder}/gaps_test_set.csv")


# ## Setup

# +
## Generate the Kfolds using GroupShuffleSplit.
## We want them to be the same for every model.
## We want num_repeats of them to be able to do Repeated KFold.
## The random_state seeds are set for reproducibility
## and are generated by their own random generator with
## a set seed.
n_splits = 10
num_repeats = 10

# Seed the random number generator and choose random_state values.
seed(15)
random_states = [randint(0, 100) for i in range(0, num_repeats)]
gss_list = [
    GroupShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=random_states[i])
    for i in range(0, num_repeats)
]

## Specify the groups that will be used for generating the folds.
groups = df_gaps_train.ssvid.to_numpy()

## Create a custom scorer based on F0.5 Score
fhalf_scorer = skm.make_scorer(skm.fbeta_score, beta=0.5, average="binary")

## Set whether the cross validation should return the estimator instances.
## Set True for debugging and investigation purposes.
## Otherwise set False to speed up execution.
return_estimator = False

## Set whether the higher computation models should run.
## Set to False when debugging or testing out new
## model selection architectures to save time.
run_double_thresh_models = True
# -

# #### Save the SSVID used in the train and test datasets in every split

# +
outfile_cv_gss_splits = f"{models_folder}/cv_gss_splits.json"

i = 0
cv_gss_splits_json = {}
for gss in gss_list:
    gss_json = []
    for temp_train_idx, temp_test_idx in gss.split(df_gaps_train, groups=groups):
        temp_gaps_train = df_gaps_train.iloc[temp_train_idx]
        temp_gaps_test = df_gaps_train.iloc[temp_test_idx]

        gss_json.append(
            {
                "train_ssvid": temp_gaps_train.ssvid.unique().tolist(),
                "test_ssvid": temp_gaps_test.ssvid.unique().tolist(),
            }
        )
    cv_gss_splits_json[f"gss{i}"] = gss_json
    i += 1


with open(outfile_cv_gss_splits, "w") as outfile:
    json.dump(cv_gss_splits_json, outfile)
# -

# ## Run the cross validation procedure for each model

# #### 12hb

# +
X = df_gaps_train[["positions_12_hours_before_sat"]].to_numpy()
y = df_gaps_train.actual_gap_class.to_numpy()

cv_results_12hb = []
for i in range(0, num_repeats):
    cv_results_12hb.append(
        cross_validate(
            SingleThresholdClassifier(),
            X,
            y,
            cv=gss_list[i],
            return_estimator=return_estimator,
            scoring=fhalf_scorer,
            groups=groups,
            n_jobs=-1,
        )
    )
# -

# #### 12hba

# +
X = df_gaps_train[
    ["positions_12_hours_before_sat", "positions_12_hours_after_sat"]
].to_numpy()
y = df_gaps_train.actual_gap_class.to_numpy()

cv_results_12hba = []
for i in range(0, num_repeats):
    cv_results_12hba.append(
        cross_validate(
            SingleThresholdClassifier(),
            X,
            y,
            cv=gss_list[i],
            return_estimator=return_estimator,
            scoring=fhalf_scorer,
            groups=groups,
            n_jobs=-1,
        )
    )
# -

# #### Xhb

# + tags=[]
X = df_gaps_train[["positions_X_hours_before_sat"]].to_numpy()
y = df_gaps_train.actual_gap_class.to_numpy()

cv_results_Xhb = []
for i in range(0, num_repeats):
    cv_results_Xhb.append(
        cross_validate(
            SingleThresholdClassifier(),
            X,
            y,
            cv=gss_list[i],
            return_estimator=return_estimator,
            scoring=fhalf_scorer,
            groups=groups,
            n_jobs=-1,
        )
    )
# -

# #### Xhba

# + tags=[]
X = df_gaps_train[
    ["positions_X_hours_before_sat", "positions_X_hours_after_sat"]
].to_numpy()
y = df_gaps_train.actual_gap_class.to_numpy()

cv_results_Xhba = []
for i in range(0, num_repeats):
    cv_results_Xhba.append(
        cross_validate(
            SingleThresholdClassifier(),
            X,
            y,
            cv=gss_list[i],
            return_estimator=return_estimator,
            scoring=fhalf_scorer,
            groups=groups,
            n_jobs=-1,
        )
    )
# -

# #### rec_only

# +
X = df_gaps_train[["positions_per_day_off"]].to_numpy()
y = df_gaps_train.actual_gap_class.to_numpy()

cv_results_rec_only = []
for i in range(0, num_repeats):
    cv_results_rec_only.append(
        cross_validate(
            SingleThresholdClassifier(),
            X,
            y,
            cv=gss_list[i],
            return_estimator=return_estimator,
            scoring=fhalf_scorer,
            groups=groups,
            n_jobs=-1,
        )
    )
# -

# #### rec_12hb

if run_double_thresh_models:
    X = df_gaps_train[
        ["positions_per_day_off", "positions_12_hours_before_sat"]
    ].to_numpy()
    y = df_gaps_train.actual_gap_class.to_numpy()

    cv_results_rec_12hb = []
    for i in range(0, num_repeats):
        cv_results_rec_12hb.append(
            cross_validate(
                DoubleThresholdClassifier(),
                X,
                y,
                cv=gss_list[i],
                return_estimator=return_estimator,
                scoring=fhalf_scorer,
                groups=groups,
                n_jobs=-1,
            )
        )


# #### rec_12hba

if run_double_thresh_models:
    X = df_gaps_train[
        [
            "positions_per_day_off",
            "positions_12_hours_before_sat",
            "positions_12_hours_after_sat",
        ]
    ].to_numpy()
    y = df_gaps_train.actual_gap_class.to_numpy()

    cv_results_rec_12hba = []
    for i in range(0, num_repeats):
        cv_results_rec_12hba.append(
            cross_validate(
                DoubleThresholdClassifier(),
                X,
                y,
                cv=gss_list[i],
                return_estimator=return_estimator,
                scoring=fhalf_scorer,
                groups=groups,
                n_jobs=-1,
            )
        )


# #### rec_Xhb

if run_double_thresh_models:
    X = df_gaps_train[
        ["positions_per_day_off", "positions_X_hours_before_sat"]
    ].to_numpy()
    y = df_gaps_train.actual_gap_class.to_numpy()

    cv_results_rec_Xhb = []
    for i in range(0, num_repeats):
        cv_results_rec_Xhb.append(
            cross_validate(
                DoubleThresholdClassifier(),
                X,
                y,
                cv=gss_list[i],
                return_estimator=return_estimator,
                scoring=fhalf_scorer,
                groups=groups,
                n_jobs=-1,
            )
        )


# #### rec_Xhba

if run_double_thresh_models:
    X = df_gaps_train[
        [
            "positions_per_day_off",
            "positions_X_hours_before_sat",
            "positions_X_hours_after_sat",
        ]
    ].to_numpy()
    y = df_gaps_train.actual_gap_class.to_numpy()

    cv_results_rec_Xhba = []
    for i in range(0, num_repeats):
        cv_results_rec_Xhba.append(
            cross_validate(
                DoubleThresholdClassifier(),
                X,
                y,
                cv=gss_list[i],
                return_estimator=return_estimator,
                scoring=fhalf_scorer,
                groups=groups,
                n_jobs=-1,
            )
        )


# ## Results

# +
test_scores_12hb = concatenate([results["test_score"] for results in cv_results_12hb])
test_scores_12hba = concatenate([results["test_score"] for results in cv_results_12hba])
test_scores_Xhb = concatenate([results["test_score"] for results in cv_results_Xhb])
test_scores_Xhba = concatenate([results["test_score"] for results in cv_results_Xhba])
test_scores_rec_only = concatenate(
    [results["test_score"] for results in cv_results_rec_only]
)

if run_double_thresh_models:
    test_scores_rec_12hb = concatenate(
        [results["test_score"] for results in cv_results_rec_12hb]
    )
    test_scores_rec_12hba = concatenate(
        [results["test_score"] for results in cv_results_rec_12hba]
    )
    test_scores_rec_Xhb = concatenate(
        [results["test_score"] for results in cv_results_rec_Xhb]
    )
    test_scores_rec_Xhba = concatenate(
        [results["test_score"] for results in cv_results_rec_Xhba]
    )

print(f"Model\t\tF0.5   Std Error")
print(f"--------------------------------")
print(f"12hb:\t\t{mean(test_scores_12hb):0.4f} ({sem(test_scores_12hb):0.4f})")
print(f"12hba:\t\t{mean(test_scores_12hba):0.4f} ({sem(test_scores_12hba):0.4f})")
print(f"Xhb:\t\t{mean(test_scores_Xhb):0.4f} ({sem(test_scores_Xhb):0.4f})")
print(f"Xhba:\t\t{mean(test_scores_Xhba):0.4f} ({sem(test_scores_Xhba):0.4f})")
print(
    f"rec_only:\t{mean(test_scores_rec_only):0.4f} ({sem(test_scores_rec_only):0.4f})"
)

if run_double_thresh_models:
    print(
        f"rec_12hb:\t{mean(test_scores_rec_12hb):0.4f} ({sem(test_scores_rec_12hb):0.4f})"
    )
    print(
        f"rec_12hba:\t{mean(test_scores_rec_12hba):0.4f} ({sem(test_scores_rec_12hba):0.4f})"
    )
    print(
        f"rec_Xhb:\t{mean(test_scores_rec_Xhb):0.4f} ({sem(test_scores_rec_Xhb):0.4f})"
    )
    print(
        f"rec_Xhba:\t{mean(test_scores_rec_Xhba):0.4f} ({sem(test_scores_rec_Xhba):0.4f})"
    )


# -

# #### Save the CV results

def results_to_json(cv_results, decimals=8):
    """Converts the cross validation results to a valid JSON object,
        changing numpy array objects to python list objects.
        Rounds to 8 decimal points by default for reduced file size.

    Parameters
    ----------
    cv_results : dict
        The results from running `cross_validate()`.
    decimales : int, default=8
        Number of significant demical points to round the values
        in the result arrays to.

    Returns
    ----------
    The cross validation results in valid JSON format.
    """
    cv_results_json = []
    for result in cv_results:

        result_json = {}
        for key in result.keys():
            result_json[key] = np.around(result[key], decimals=decimals).tolist()
        cv_results_json.append(result_json)

    return cv_results_json


# +
outfile_cv_results = f"{models_folder}/cv_results.json"

results_json = {
    "cv_results_12hb": results_to_json(cv_results_12hb),
    "cv_results_12hba": results_to_json(cv_results_12hba),
    "cv_results_Xhb": results_to_json(cv_results_Xhb),
    "cv_results_Xhba": results_to_json(cv_results_Xhba),
    "cv_results_rec_only": results_to_json(cv_results_rec_only),
    "cv_results_rec_12hb": results_to_json(cv_results_rec_12hb),
    "cv_results_rec_12hba": results_to_json(cv_results_rec_12hba),
    "cv_results_rec_Xhb": results_to_json(cv_results_rec_Xhb),
    "cv_results_rec_Xhba": results_to_json(cv_results_rec_Xhba),
}

with open(outfile_cv_results, "w") as outfile:
    json.dump(results_json, outfile)
# -

# # Train the best model on the full training set to get the final model

# +
X_train = df_gaps_train[["positions_X_hours_before_sat"]].to_numpy()
y_train = df_gaps_train.actual_gap_class.to_numpy()

final_model = SingleThresholdClassifier(model_name="Xhb")
final_model.fit(X_train, y_train)
final_model.save(f"{models_folder}/final_model.json")
print(f"Final model: k={final_model.k_} ({final_model.optimal_score_:0.4f})")
# -

# # Evaluate the model on the test set

# +
X_test = df_gaps_test[["positions_X_hours_before_sat"]].to_numpy()
y_true = df_gaps_test.actual_gap_class.to_numpy()
y_pred = final_model.predict(X_test)

print(
    f"The F0.5 score on the 30% independent test set is {skm.fbeta_score(y_true, y_pred, beta=0.5, average='binary'):0.4f}"
)
# -



# # Fit each of the models to the training set for visualizations
#
# Save each to file to be loaded up by separate notebooks.

# +
y = df_gaps_train.actual_gap_class.to_numpy()

# 12hb
X = df_gaps_train[["positions_12_hours_before_sat"]].to_numpy()
model_12hb = SingleThresholdClassifier(model_name="12hb")
model_12hb.fit(X, y)
model_12hb.save(f"{models_folder}/model_12hb.json")
print(f"12hb: k={model_12hb.k_} ({model_12hb.optimal_score_:0.4f})")

# 12hba
X = df_gaps_train[
    ["positions_12_hours_before_sat", "positions_12_hours_after_sat"]
].to_numpy()
model_12hba = SingleThresholdClassifier(model_name="12hba")
model_12hba.fit(X, y)
model_12hba.save(f"{models_folder}/model_12hba.json")
print(f"12hba: k={model_12hba.k_} ({model_12hba.optimal_score_:0.4f})")

# Xhb
X = df_gaps_train[["positions_X_hours_before_sat"]].to_numpy()
model_Xhb = SingleThresholdClassifier(model_name="Xhb")
model_Xhb.fit(X, y)
model_Xhb.save(f"{models_folder}/model_Xhb.json")
print(f"Xhb: k={model_Xhb.k_} ({model_Xhb.optimal_score_:0.4f})")

# Xhba
X = df_gaps_train[
    ["positions_X_hours_before_sat", "positions_X_hours_after_sat"]
].to_numpy()
model_Xhba = SingleThresholdClassifier(model_name="Xhba")
model_Xhba.fit(X, y)
model_Xhba.save(f"{models_folder}/model_Xhba.json")
print(f"Xhba: k={model_Xhba.k_} ({model_Xhba.optimal_score_:0.4f})")

# rec_only
X = df_gaps_train[["positions_per_day_off"]].to_numpy()
model_rec_only = SingleThresholdClassifier(model_name="rec_only")
model_rec_only.fit(X, y)
model_rec_only.save(f"{models_folder}/model_rec_only.json")
print(f"rec_only: j={model_rec_only.k_} ({model_rec_only.optimal_score_:0.4f})")

if run_double_thresh_models:
    # rec_12hb
    X = df_gaps_train[
        ["positions_per_day_off", "positions_12_hours_before_sat"]
    ].to_numpy()
    model_rec_12hb = DoubleThresholdClassifier(model_name="rec_12hb")
    model_rec_12hb.fit(X, y)
    model_rec_12hb.save(f"{models_folder}/model_rec_12hb.json")
    print(
        f"rec_12hb: k={model_rec_12hb.k_}, j={model_rec_12hb.j_} ({model_rec_12hb.optimal_score_:0.4f})"
    )

    # rec_12hba
    X = df_gaps_train[
        [
            "positions_per_day_off",
            "positions_12_hours_before_sat",
            "positions_12_hours_after_sat",
        ]
    ].to_numpy()
    model_rec_12hba = DoubleThresholdClassifier(model_name="rec_12hba")
    model_rec_12hba.fit(X, y)
    model_rec_12hba.save(f"{models_folder}/model_rec_12hba.json")
    print(
        f"rec_12hba: k={model_rec_12hba.k_}, j={model_rec_12hba.j_} ({model_rec_12hba.optimal_score_:0.4f})"
    )

    # rec_Xhb
    X = df_gaps_train[
        ["positions_per_day_off", "positions_X_hours_before_sat"]
    ].to_numpy()
    model_rec_Xhb = DoubleThresholdClassifier(model_name="rec_Xhb")
    model_rec_Xhb.fit(X, y)
    model_rec_Xhb.save(f"{models_folder}/model_rec_Xhb.json")
    print(
        f"rec_Xhb: k={model_rec_Xhb.k_}, j={model_rec_Xhb.j_} ({model_rec_Xhb.optimal_score_:0.4f})"
    )

    # rec_Xhba
    X = df_gaps_train[
        [
            "positions_per_day_off",
            "positions_X_hours_before_sat",
            "positions_X_hours_after_sat",
        ]
    ].to_numpy()
    model_rec_Xhba = DoubleThresholdClassifier(model_name="rec_Xhba")
    model_rec_Xhba.fit(X, y)
    model_rec_Xhba.save(f"{models_folder}/model_rec_Xhba.json")
    print(
        f"rec_Xhba: k={model_rec_Xhba.k_}, j={model_rec_Xhb.j_} ({model_rec_Xhba.optimal_score_:0.4f})"
    )
# -









# ---
# # Additional Exploration

# ## Showing the need for grouping by MMSI

# ### Cross Validation with default ShuffleSplit

# +
X = df_gaps.positions_X_hours_before_sat.to_numpy().reshape(-1, 1)
y = df_gaps.actual_gap_class.to_numpy()

model = SingleThresholdClassifier(model_name="Xhb")

fhalf_scorer = skm.make_scorer(skm.fbeta_score, beta=0.5, average="binary")
cv_results = cross_validate(
    model, X, y, cv=10, return_estimator=True, scoring=fhalf_scorer, n_jobs=-1
)
# -

scores = cv_results["test_score"]
print(f"Scores: {[round(s, 3) for s in scores]}")
print(f"Mean: {mean(scores):0.3f}; Stdev: {std(scores):0.3f}")

# ### The scoring out of the cross validation is unstable.
#
# Using GroupShuffleSplit with MMSI as the groups appears to stabilize the model with very similar f0.5 scores on each fold.

# +
X = df_gaps.positions_X_hours_before_sat.to_numpy().reshape(-1, 1)
y = df_gaps.actual_gap_class.to_numpy()
groups = df_gaps.ssvid.to_numpy()

model_gss = SingleThresholdClassifier(model_name="Xhb")

fhalf_scorer = skm.make_scorer(skm.fbeta_score, beta=0.5, average="binary")
gss_cv = GroupShuffleSplit(n_splits=10)
gss_cv_results = cross_validate(
    model_gss,
    X,
    y,
    cv=gss_cv,
    return_estimator=True,
    scoring=fhalf_scorer,
    groups=groups,
    n_jobs=-1,
)
# -

gss_scores = gss_cv_results["test_score"]
print(f"Scores: {[round(s, 3) for s in gss_scores]}")
print(f"Mean: {mean(gss_scores):0.3f}; Stdev: {std(gss_scores):0.3f}")

# ## Showing that GroupShuffleSplit gives reasonable stratificaiton in the classes without explicit stratification 
#
# The percentage of gaps that are True vs False are nearly the same in all train and test sets with the basic GroupShuffleSplit so no additional stratification was necessary.

for train_ix, test_ix in gss_cv.split(X, y, groups=groups):
    train_X, test_X = X[train_ix], X[test_ix]
    train_y, test_y = y[train_ix], y[test_ix]
    # summarize train and test composition
    train_0, train_1 = len(train_y[train_y == 0]) / len(train_y), len(
        train_y[train_y == 1]
    ) / len(train_y)
    test_0, test_1 = len(test_y[test_y == 0]) / len(test_y), len(
        test_y[test_y == 1]
    ) / len(test_y)
    print(
        ">Train: False=%0.2f, True=%0.2f -- Test: False=%0.2f, True=%0.2f"
        % (train_0, train_1, test_0, test_1)
    )


